{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd7ab486-ad90-4e67-a082-df92c5905de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from moralstrength.moralstrength import estimate_morals\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af3e0c8-c651-4e4e-b470-273b194c1a9c",
   "metadata": {},
   "source": [
    "# MoralStrength features\n",
    "\n",
    "This notebook contains the necessary functions to elicit the moral and emotional value of texts using the lexical-based approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50561db9-f958-43a2-b9d8-aa4b9898e490",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# MFTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2e9ea0-abba-4bf7-906e-2526be0d201d",
   "metadata": {},
   "source": [
    "## 1 Moral "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c6cce-121a-4e86-a6ce-2eb3d216b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_values(values):\n",
    "    \"\"\"\n",
    "    Classifies moral values based on their polarity.\n",
    "    \n",
    "    Args:\n",
    "    values (dict): Dictionary with moral values where the key is the name of the moral value\n",
    "                   and the value is the associated score.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary with moral values classified into their respective polarities.\n",
    "    \"\"\"\n",
    "    classification = {}\n",
    "\n",
    "    for moral, value in values.items():\n",
    "        if moral == 'care':\n",
    "            if value > 5:\n",
    "                classification['care'] = value\n",
    "            elif value < 5:\n",
    "                classification['harm'] = value\n",
    "        elif moral == 'fairness':\n",
    "            if value > 5:\n",
    "                classification['fairness'] = value\n",
    "            elif value < 5:\n",
    "                classification['cheating'] = value\n",
    "        elif moral == 'loyalty':\n",
    "            if value > 5:\n",
    "                classification['loyalty'] = value\n",
    "            elif value < 5:\n",
    "                classification['betrayal'] = value\n",
    "        elif moral == 'authority':\n",
    "            if value > 5:\n",
    "                classification['authority'] = value\n",
    "            elif value < 5:\n",
    "                classification['subversion'] = value\n",
    "        elif moral == 'purity':\n",
    "            if value > 5:\n",
    "                classification['purity'] = value\n",
    "            elif value < 5:\n",
    "                classification['degradation'] = value\n",
    "\n",
    "    return classification\n",
    "\n",
    "'''\n",
    "# Apply functions\n",
    "alm_cleaned=pd.read_csv('DATASETS/ALM_polarity.csv')\n",
    "blm_cleaned=pd.read_csv('DATASETS/BLM_polarity.csv')\n",
    "baltimore_cleaned=pd.read_csv('DATASETS/BALTIMORE_polarity.csv')\n",
    "davidson_cleaned=pd.read_csv('DATASETS/DAVIDSON_polarity.csv')\n",
    "election_cleaned=pd.read_csv('DATASETS/ELECTION_polarity.csv')\n",
    "sandy_cleaned=pd.read_csv('DATASETS/SANDY_polarity.csv')\n",
    "\n",
    "\n",
    "datasets = [\n",
    "    ('alm_cleaned', 'DATASETS/ALM_polarity.csv'),\n",
    "    ('blm_cleaned', 'DATASETS/BLM_polarity.csv'),\n",
    "    ('baltimore_cleaned', 'DATASETS/BALTIMORE_polarity.csv'),\n",
    "    ('davidson_cleaned', 'DATASETS/DAVIDSON_polarity.csv'),\n",
    "    ('election_cleaned', 'DATASETS/ELECTION_polarity.csv'),\n",
    "    ('sandy_cleaned', 'DATASETS/SANDY_polarity.csv')\n",
    "]\n",
    "\n",
    "for dataset_name, file_path in datasets:\n",
    "    df = globals()[dataset_name] \n",
    "    df = prompt_moralstrength(df)\n",
    "    df['moralstrength_base'] = df['moralstrength'].apply(lambda x: classify_values(x))\n",
    "    df['moralstrength'] = df['moralstrength_base'].apply(lambda x: moralstrength_differences(x))\n",
    "    df['prompt'] = df['moralstrength'].apply(lambda x: moralstrength_max_moral(x))\n",
    "    df.drop('moralstrength', axis=1, inplace=True)\n",
    "    df.to_csv(file_path.replace('_polarity.csv', '_moralstrength_estimation_polarity.csv'), index=False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26065b08-c2eb-4162-9221-093b4f4b831b",
   "metadata": {},
   "source": [
    "## SEVERAL MORALS AND INTENSITIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cdc674-f440-49d4-a916-c6d50132134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def moralstrength_intensities(values):\n",
    "    \"\"\"\n",
    "    Calculates the differences of the value from 5 and classifies the intensity as low, medium, or high.\n",
    "    \n",
    "    Args:\n",
    "    valores (dict): Dictionary with moral values where the key is the name of the moral value\n",
    "                    and the value is the associated score.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary with moral values and their classified intensities:\n",
    "          - 'high' for difference > 2.5\n",
    "          - 'medium' for 1.5 < difference <= 2.5\n",
    "          - 'low' for difference <= 1.5\n",
    "    \"\"\"\n",
    "    \n",
    "    #calcula las diferencias del valor al 5 y dependiendo de esa distancia se clasifica como intensidad media baja alta\n",
    "    classification = {}\n",
    "    for moral, value in valores.items():\n",
    "        if value != 0:\n",
    "            difference = abs(value - 5)  # Calculate the difference from 5\n",
    "            if difference > 2.5:  # Large difference\n",
    "                classification[moral] = \"high\"\n",
    "            elif difference > 1.5:  # Moderate difference\n",
    "                classification[moral] = \"medium\"\n",
    "            else:  # Small difference\n",
    "                classification[moral] = \"low\"\n",
    "    \n",
    "    return classification\n",
    "    \n",
    "\n",
    "def moralstrength_intensities_prompt(text):\n",
    "    \"\"\"\n",
    "    Creates a prompt with the information of moral value intensities.\n",
    "    \n",
    "    Args:\n",
    "    text (dict): Dictionary with moral values and their classified intensities.\n",
    "    \n",
    "    Returns:\n",
    "    str: A prompt string with the moral values and their intensities.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return 'no moral'\n",
    "    \n",
    "    prompt = ' '\n",
    "    for moral, intensity in text.items():\n",
    "        prompt += f\"{moral}: {intensity}, \"\n",
    "    \n",
    "    return prompt.strip(', ')  # Remove the trailing comma and space\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "#Apply Functions\n",
    "alm_cleaned=pd.read_csv('DATASETS/ALM_polarity.csv')\n",
    "blm_cleaned=pd.read_csv('DATASETS/BLM_polarity.csv')\n",
    "baltimore_cleaned=pd.read_csv('DATASETS/BALTIMORE_polarity.csv')\n",
    "davidson_cleaned=pd.read_csv('DATASETS/DAVIDSON_polarity.csv')\n",
    "election_cleaned=pd.read_csv('DATASETS/ELECTION_polarity.csv')\n",
    "sandy_cleaned=pd.read_csv('DATASETS/SANDY_polarity.csv')\n",
    "\n",
    "datasets = [\n",
    "    ('alm_cleaned', 'DATASETS/ALM_polarity.csv'),\n",
    "    ('blm_cleaned', 'DATASETS/BLM_polarity.csv'),\n",
    "    ('baltimore_cleaned', 'DATASETS/BALTIMORE_polarity.csv'),\n",
    "    ('davidson_cleaned', 'DATASETS/DAVIDSON_polarity.csv'),\n",
    "    ('election_cleaned', 'DATASETS/ELECTION_polarity.csv'),\n",
    "    ('sandy_cleaned', 'DATASETS/SANDY_polarity.csv')\n",
    "]\n",
    "\n",
    "for dataset_name, file_path in datasets:\n",
    "    df = globals()[dataset_name]  # Obtiene el DataFrame por su nombre\n",
    "    df = prompt_moralstrength(df)\n",
    "    df['moralstrength_base'] = df['moralstrength'].apply(lambda x: classify_values(x))\n",
    "    df['moralstrength'] = df['moralstrength_base'].apply(lambda x: moralstrength_intensities(x))\n",
    "    df['prompt'] = df['moralstrength'].apply(lambda x: moralstrength_intensities_prompt(x))\n",
    "    df.drop('moralstrength', axis=1, inplace=True)\n",
    "    df.to_csv(file_path.replace('_polarity.csv', '_moralstrength_estimate_low_medium_high_polarity.csv'), index=False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43482b88-f606-41cf-b114-17e10b6c4cfc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# MFRC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4c2ffd-f7a3-4b6a-a96e-b106416dc74f",
   "metadata": {},
   "source": [
    "## 1 Moral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a4225e-eefa-4598-b46a-382faa7d6ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df = df_reddit.copy()\n",
    "df = prompt_moralstrength(df)\n",
    "df['moralstrength'] = df['moralstrength'].apply(lambda x: moralstrength_differences(x))\n",
    "df['prompt'] = df['moralstrength'].apply(lambda x: moralstrength_max_moral(x))\n",
    "#df.drop('moralstrength', axis=1, inplace=True)\n",
    "#df.to_csv('DATASETS/REDDIT_moralstrength_estimate.csv', index=False)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de12141-9b61-4900-a3fe-9edc886bdebb",
   "metadata": {},
   "source": [
    "## SEVERAL MORALS AND INTENSITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7dde11-f359-4340-aba3-dd87cd57c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df_reddit=pd.read_csv('DATASETS/CLEAN/REDDIT_clean.csv')\n",
    "df_reddit= df_reddit.replace({'label': {'Care': 'care', 'Harm': 'harm',\n",
    "                            'Fairness': 'fairness','Cheating': 'cheating',\n",
    "                            'Loyalty': 'loyalty','Betrayal': 'betrayal',\n",
    "                            'Authority': 'authority','Subversion': 'subversion',\n",
    "                             'Purity':  'purity','Degradation': 'degradation','Thin Morality': 'non-moral'}})\n",
    "df_reddit\n",
    "\n",
    "\n",
    "df = df_reddit.copy()\n",
    "df = prompt_moralstrength(df)\n",
    "df['moralstrength'] = df['moralstrength'].apply(lambda x: moralstrength_intensities(x))\n",
    "df['prompt'] = df['moralstrength'].apply(lambda x: moralstrength_intensities_prompt(x))\n",
    "df.drop('moralstrength', axis=1, inplace=True)\n",
    "\n",
    "df.to_csv('DATASETS/REDDIT_moralstrength_estimate_low_medium_high.csv', index=False)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

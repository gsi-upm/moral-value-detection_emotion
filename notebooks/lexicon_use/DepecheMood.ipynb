{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36527ad2-8ce8-4cf3-b2ce-4c8d3531ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import models\n",
    "import functools\n",
    "import numpy as np\n",
    "import warnings\n",
    "import operator\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53835d9-a153-4db7-9e50-92dc3fa44137",
   "metadata": {},
   "source": [
    "# Depechemood++ features\n",
    "This notebook contains the necessary functions to elicit the moral and emotional value of texts using the lexical-based approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94d59a-c302-476e-99dd-9843f43f0d78",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc43db74-eeb5-4f3e-b7a9-e66eca08611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emo_transform(data, emotion_lex, n_emotions):\n",
    "    \"\"\"\n",
    "    Transforms text data into emotion representations using a given emotion lexicon.\n",
    "    \n",
    "    Args:\n",
    "    data (pd.DataFrame): DataFrame containing text data with a 'text' column.\n",
    "    emotion_lex (dict): Dictionary mapping words to their emotion vectors.\n",
    "    n_emotions (int): Number of emotions in the emotion vectors.\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary where keys are row indices and values are emotion representations.\n",
    "    \"\"\"\n",
    "    \n",
    "    emo_vocab = set(emotion_lex.keys())\n",
    "    emo_values = {}\n",
    "    for idx, row in data.iterrows():\n",
    "        text = row['text']\n",
    "        emo_values[idx] = extract_emo_representation(text.split(' '), emo_vocab, emotion_lex, n_emotions)\n",
    "    return emo_values\n",
    "\n",
    "\n",
    "def extract_emo_representation(words, emo_vocab=None, emotion_lex=None, n_emotions=None):\n",
    "    \"\"\"\n",
    "    Extracts an emotion representation from a list of words.\n",
    "    \n",
    "    Args:\n",
    "    words (list of str): List of words from the text.\n",
    "    emo_vocab (set): Set of words in the emotion lexicon.\n",
    "    emotion_lex (dict): Dictionary mapping words to their emotion vectors.\n",
    "    n_emotions (int): Number of emotions in the emotion vectors.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: Concatenated mean emotion representation vector.\n",
    "    \"\"\"\n",
    "    intersection = emo_vocab & set(words)\n",
    "    v = np.zeros((len(intersection), n_emotions))\n",
    "    for i, word in enumerate(intersection):\n",
    "        v[i, :] = emotion_lex[word] \n",
    "    return np.concatenate((\n",
    "        np.mean(v, axis=0),\n",
    "        #np.max(v, axis=0),\n",
    "    ), axis=0)\n",
    "    \n",
    "def dictionary_emotion(text):\n",
    "    \"\"\"\n",
    "    Converts a list of emotion scores into a dictionary with emotion labels as keys.\n",
    "    \n",
    "    Args:\n",
    "    text (list): List of emotion scores.\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary mapping emotion labels to their respective scores.\n",
    "    \"\"\"\n",
    "    test_keys = [\"fear\", \"amusement\", \"anger\",\"annoyance\",\"indifference\",\"happiness\",\"inspiration\",\"sadness\"]\n",
    "    dictionary = dict(map(lambda i,j : (i,j) , test_keys,text))\n",
    "    return dictionary\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "def prompt_function(text):  \n",
    "    \"\"\"\n",
    "    Creates a prompt with the top 4 emotions based on their scores.\n",
    "    \n",
    "    Args:\n",
    "    text (dict): Dictionary mapping emotion labels to their respective scores.\n",
    "    \n",
    "    Returns:\n",
    "    str: A comma-separated string of the top 4 emotions.\n",
    "    \"\"\"\n",
    "    sorted_dict = dict(sorted(text.items(), key=operator.itemgetter(1),reverse=True))    \n",
    "    n_items = list(islice(sorted_dict.items(),4))\n",
    "    n_items\n",
    "    prompt=([i[0] for i in n_items])\n",
    "    prompt= ', '.join(prompt)\n",
    "    return prompt\n",
    "    \n",
    "def max_emotion(text):\n",
    "    \"\"\"\n",
    "    Finds the emotion with the highest score.\n",
    "    \n",
    "    Args:\n",
    "    text (dict): Dictionary mapping emotion labels to their respective scores.\n",
    "    \n",
    "    Returns:\n",
    "    str: The emotion label with the highest score.\n",
    "    \"\"\"\n",
    "    max_moral = max(text, key=text.get)\n",
    "    return max_moral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5f875d-e4f2-4d88-b135-b97b0b66fcda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f32f98ab-56a3-4bf1-ad52-8aaa59c7207c",
   "metadata": {},
   "source": [
    "# DepecheMood++ Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ac2ba-69a5-43b8-a92f-2befd4ef4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the DepecheMood lexicon\n",
    "#lexicon=pd.read_csv('DATASETS/DepecheMood_english_lemma_full.tsv',sep='\\t',index_col=[0])\n",
    "#lexicon.to_csv('DATASETS/DepecheMood_english_lemma_full.csv')\n",
    "\n",
    "#Filter lexicon to include only rows with 'freq' >= , 134278 values were discarded (23%), 41314 lemmas\n",
    "lexicon=pd.read_csv('DATASETS/DepecheMood_english_lemma_full.csv',index_col=[0])\n",
    "lexicon=lexicon[lexicon['freq'] >= 10] \n",
    "\n",
    "#Convert the lexicon to a dictionary\n",
    "lexicon=lexicon.drop('freq',axis=1)\n",
    "lexicon=lexicon.reset_index()\n",
    "lexicon_dict = lexicon.set_index('index').T.to_dict('list')\n",
    "lexicon_dict\n",
    "lexicon.loc[200:250,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc43e20-2172-4da1-891c-72bfa35f72d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example \n",
    "emo_vocab = set(lexicon_dict.keys())\n",
    "emo_values = {}\n",
    "text='''My cat is not loyal.'''\n",
    "data=extract_emo_representation(text.split(' '), emo_vocab, lexicon_dict, 8) \n",
    "data=dictionary_emotion(data)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d4fac8-596f-4031-9ce7-a26bc704444e",
   "metadata": {},
   "source": [
    "# MFRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16011cef-4467-4955-9525-f2d1a1f96475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a single dataset with MoralStrength and DepecheMood++ lexicons\n",
    "\n",
    "reddit1=pd.read_csv('DATASETS/REDDIT_moralstrength_estimate.csv')\n",
    "reddit1=reddit1[['text','prompt']]\n",
    "reddit1=reddit1.rename(columns={'prompt': 'moralstrength'}) \n",
    "reddit1.drop_duplicates(subset=['text'],inplace=True)\n",
    "reddit1\n",
    "\n",
    "reddit2=pd.read_csv('DATASETS/REDDIT_moralstrength_estimate_low_medium_high.csv')\n",
    "reddit2=reddit2[['text','label','prompt']]\n",
    "reddit2=reddit2.rename(columns={'prompt': 'moralstrength_i'}) \n",
    "reddit2.drop_duplicates(subset=['text'],inplace=True)\n",
    "reddit2\n",
    "\n",
    "\n",
    "reddit3=reddit2.merge(reddit1,on='text',how='outer')\n",
    "reddit3\n",
    "\n",
    "\n",
    "reddit3['depechemood'] = emo_transform(reddit, lexicon_dict, 8)\n",
    "reddit3\n",
    "\n",
    "reddit3['dictionary_emotions']=reddit3['depechemood'].apply(lambda x: dictionary_emotion(x))\n",
    "reddit3['emotion_word']=reddit3['dictionary_emotions'].apply(max_emotion)\n",
    "reddit3['prompt']=reddit3['dictionary_emotions'].apply(lambda x:prompt_function(x))\n",
    "reddit3\n",
    "reddit3.to_csv('DATASETS/REDDIT_dataset.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae249af6-a6d2-44d8-a0ee-af42c4ab5671",
   "metadata": {},
   "source": [
    "# MFTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69033c7-5b2e-45ba-8e9e-79cf65096f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a single dataset\n",
    "\n",
    "datasets = ['ALM', 'BLM', 'BALTIMORE', 'DAVIDSON', 'ELECTION', 'SANDY']\n",
    "\n",
    "# Function to process each dataset\n",
    "def process_mftc(name):\n",
    "    # Load the CSV (1 moral value)\n",
    "    data1 = pd.read_csv(f'DATASETS/{name}_moralstrength_estimate_polarity.csv')\n",
    "    data1 = data1[['text', 'prompt']]\n",
    "    data1 = data1.rename(columns={'prompt': 'moralstrength'})\n",
    "    data1.drop_duplicates(subset=['text'], inplace=True)\n",
    "\n",
    "    # Load the CSV (several moral values and intensities)\n",
    "    data2 = pd.read_csv(f'DATASETS/{name}_moralstrength_estimate_low_medium_high_polarity.csv')\n",
    "    data2 = data2[['text', 'label', 'prompt']]\n",
    "    data2 = data2.rename(columns={'prompt': 'moralstrength_i'})\n",
    "    data2.drop_duplicates(subset=['text'], inplace=True)\n",
    "\n",
    "    data3 = data2.merge(data1, on='text', how='outer')\n",
    "\n",
    "    # # Apply dictionary emotion function\n",
    "    data3['depechemood'] = emo_transform(data3, lexicon_dict, 8)\n",
    "    data3['dictionary_emotions'] = data3['depechemood'].apply(lambda x: dictionary_emotion(x))\n",
    "    data3['emotion_word'] = data3['dictionary_emotions'].apply(max_emotion)\n",
    "    data3['prompt'] = data3['dictionary_emotions'].apply(lambda x: prompt_function(x))\n",
    "\n",
    "    #data3.to_csv(f'DATASETS/{name}_dataset.csv', index=False)\n",
    "\n",
    "for dataset in datasets:\n",
    "    process_mftc(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfaf58a-9a59-4c0b-88ee-9dd660f82ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

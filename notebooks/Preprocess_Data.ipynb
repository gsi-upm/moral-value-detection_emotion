{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394a4430-b4c5-4eea-9a72-e1bb980e0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "import re\n",
    "import spacy\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from ekphrasis.classes.segmenter import Segmenter\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc82c89-2f17-47fd-88d9-c6b9891b2cab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LOAD AND PRE-PROCESS DATASETS MFTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584e92df-ef2e-4891-a28d-860d9553d5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD DATASETS\n",
    "\n",
    "#ALM\n",
    "alm=pd.read_csv('DATASETS/MFTC/ALM.tsv',sep='\\t')\n",
    "alm = alm.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "#BALTIMORE\n",
    "baltimore=pd.read_csv('DATASETS/MFTC/Baltimore.tsv',sep='\\t')\n",
    "baltimore = baltimore.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "#BLM\n",
    "with open('DATASETS/MFTC/BLM.tsv', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "column_names = lines[0].strip().split('\\t')\n",
    "dataset = [dict(zip(column_names, line.strip().split('\\t')[1:])) for line in lines[1:]]\n",
    "blm = pd.DataFrame(dataset)\n",
    "blm['annotations'] = blm['annotations'].apply(lambda x: json.loads(x.replace(\"'\", \"\\\"\")) if isinstance(x, str) else x)\n",
    "\n",
    "#DAVIDSON - hate speech and offensive language\n",
    "davidson=pd.read_csv('DATASETS/MFTC/Davidson.tsv',sep='\\t')\n",
    "davidson = davidson.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "#ELECTION\n",
    "election=pd.read_csv('DATASETS/MFTC/Election.tsv',sep='\\t')\n",
    "election = election.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "#SANDY\n",
    "sandy=pd.read_csv('DATASETS/MFTC/Sandy.tsv',sep='\\t')\n",
    "sandy = sandy.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "#REDDIT\n",
    "reddit=pd.read_csv('DATASETS/final_mfrc_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f0061-01d2-430f-ab39-a8cafa4f49e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix problems reading datasets\n",
    "\n",
    "#BLM\n",
    "def index_list_blm(df):\n",
    "    df_new=df.dropna(how='all').reset_index(drop=True)\n",
    "    df_new.head(10)\n",
    "    nan_index= df_new.index[df_new['annotations'].isna()].tolist()\n",
    "    nan_index_plus1 = [idx + 1 for idx in nan_index]\n",
    "    nan_index_plus1= nan_index_plus1[0::2]\n",
    "    return nan_index_plus1, df_new\n",
    "    \n",
    "def blm_dataset(df): \n",
    "    nan_index_plus1, df_new = index_list_blm(df)\n",
    "    blm_cleaned=df_new.copy()\n",
    "    id_list = blm_cleaned['id'].tolist()\n",
    "    text_list = blm_cleaned['text'].tolist()\n",
    "    annotations_list = blm_cleaned['annotations'].tolist()\n",
    "    label_list = blm_cleaned['label'].tolist()\n",
    "    \n",
    "    id_dict = dict(zip(blm_cleaned.index, id_list))\n",
    "    text_dict = dict(zip(blm_cleaned.index, text_list))\n",
    "    annotations_dict = dict(zip(blm_cleaned.index, annotations_list))\n",
    "    label_dict = dict(zip(blm_cleaned.index, label_list))\n",
    "    \n",
    "    nan_indices_annotations = blm_cleaned.index[blm_cleaned['annotations'].isna()].tolist()\n",
    "    nan_indices_label = blm_cleaned.index[blm_cleaned['label'].isna()].tolist()\n",
    "    \n",
    "    for idx in nan_indices_annotations:\n",
    "        blm_cleaned.at[idx, 'annotations'] = [{'annotation': id_dict[idx + 1], 'annotator': 'annotator0'}]\n",
    "    \n",
    "    for idx in nan_indices_label:\n",
    "        blm_cleaned.at[idx, 'label'] = text_dict[idx + 1]\n",
    "    \n",
    "    df_result = pd.DataFrame({\n",
    "        'id': blm_cleaned['id'],\n",
    "        'text': blm_cleaned['text'],\n",
    "        'annotations': blm_cleaned['annotations'],\n",
    "        'label': blm_cleaned['label']\n",
    "    })\n",
    "    df_result = df_result.drop(df_result[df_result.index.isin(nan_index_plus1)].index)\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "#ALM\n",
    "def alm_dataset(df):\n",
    "    df.loc[1315, 'annotations'] = df.loc[1316, 'id']\n",
    "    df.loc[1315, 'label'] = df.loc[1316, 'text']\n",
    "\n",
    "    df.loc[2247, 'annotations'] = df.loc[2248, 'id']\n",
    "    df.loc[2247, 'label'] = df.loc[2248, 'text']\n",
    "\n",
    "    df = df.drop([1316, 2248])\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "#ELECTION\n",
    "def election_dataset(df):\n",
    "    df.loc[394, 'annotations'] = df.loc[395, 'id']\n",
    "    df.loc[394, 'label'] = df.loc[395, 'text']\n",
    "    df = df.drop([395])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210bf3c1-2dab-4a97-9391-9337e2ce02cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LABELS BINARY (MPres)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881bb8f5-a1cf-4137-82fd-4eda71f22fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Change label from categorical to int depends on the moral trait (MPres task)\n",
    "    Moral Values: Moral1: care/harm\n",
    "                  Moral2: fairness/cheating\n",
    "                  Moral3: loyalty/betrayal\n",
    "                  Moral4: authority/subversion\n",
    "                  Moral5: purity/degradation'''\n",
    "\n",
    "def labels_m1(df):\n",
    "    df= df.replace({'label': {'care': 1, 'harm': 1,\n",
    "                                'fairness': 0,'cheating': 0,\n",
    "                                'loyalty': 0,'betrayal': 0,\n",
    "                                'authority': 0,'subversion': 0,\n",
    "                                 'purity': 0,'degradation': 0,'non-moral': 0,'nonmoral': 0}})\n",
    "    return df\n",
    "\n",
    "\n",
    "def labels_m2(df):\n",
    "    df= df.replace({'label': {'care': 0, 'harm': 0,\n",
    "                                'fairness': 1,'cheating': 1,\n",
    "                                'loyalty': 0,'betrayal': 0,\n",
    "                                'authority': 0,'subversion': 0,\n",
    "                                 'purity': 0,'degradation': 0,'non-moral': 0, 'nonmoral': 0 }})\n",
    "    return df\n",
    "\n",
    "\n",
    "def labels_m3(df):\n",
    "    df= df.replace({'label': {'care': 0, 'harm': 0,\n",
    "                                'fairness': 0,'cheating': 0,\n",
    "                                'loyalty': 1,'betrayal': 1,\n",
    "                                'authority': 0,'subversion': 0,\n",
    "                                 'purity': 0,'degradation': 0,'non-moral': 0,'nonmoral': 0}})\n",
    "    return df\n",
    "\n",
    "\n",
    "def labels_m4(df):\n",
    "    df= df.replace({'label': {'care': 0, 'harm': 0,\n",
    "                                'fairness': 0,'cheating': 0,\n",
    "                                'loyalty': 0,'betrayal': 0,\n",
    "                                'authority': 1,'subversion': 1,\n",
    "                                 'purity': 0,'degradation': 0,'non-moral': 0,'nonmoral': 0}})\n",
    "    return df\n",
    "\n",
    "def labels_m5(df):\n",
    "    df= df.replace({'label': {'care': 0, 'harm': 0,\n",
    "                                'fairness': 0,'cheating': 0,\n",
    "                                'loyalty': 0,'betrayal': 0,\n",
    "                                'authority': 0,'subversion': 0,\n",
    "                                 'purity': 1,'degradation': 1,'non-moral': 0,'nonmoral': 0 }})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb88b56d-36f3-4dd5-b815-c49bffd7bbce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LABELS POLARITY (MPol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af414f75-7c91-43be-bc98-02169deac184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the label from categorical to int depends on the moral trait and distinguishing its polarity (vice or virtue).\n",
    "\n",
    "def label_mp1(df):\n",
    "    df= df.replace({'label': {'care': 1, 'harm': 2,\n",
    "                                'fairness': 0,'cheating': 0,\n",
    "                                'loyalty': 0,'betrayal': 0,\n",
    "                                'authority': 0,'subversion': 0,\n",
    "                                 'purity': 0,'degradation': 0,'non-moral': 0,'nonmoral': 0,'nm': 0\n",
    "                                }})\n",
    "    return df\n",
    "\n",
    "\n",
    "def label_mp2(df):\n",
    "    df= df.replace({'label': {'care': 0, 'harm': 0,\n",
    "                                'fairness': 1,'cheating': 2,\n",
    "                                'loyalty': 0,'betrayal': 0,\n",
    "                                'authority': 0,'subversion': 0,\n",
    "                                 'purity': 0,'degradation': 0,'non-moral': 0, 'nonmoral': 0,'nm': 0\n",
    "                                }})\n",
    "    return df\n",
    "\n",
    "\n",
    "def label_mp3(df):\n",
    "    df= df.replace({'label': {'care': 0, 'harm': 0,\n",
    "                                'fairness': 0,'cheating': 0,\n",
    "                                'loyalty': 1,'betrayal': 2,\n",
    "                                'authority': 0,'subversion': 0,\n",
    "                                 'purity': 0,'degradation': 0,'non-moral': 0,'nonmoral': 0,'nm': 0\n",
    "                                }})\n",
    "    return df\n",
    "\n",
    "\n",
    "def label_mp4(df):\n",
    "    df= df.replace({'label': {'care': 0, 'harm': 0,\n",
    "                                'fairness': 0,'cheating': 0,\n",
    "                                'loyalty': 0,'betrayal': 0,\n",
    "                                'authority': 1,'subversion': 2,\n",
    "                                 'purity': 0,'degradation': 0,'non-moral': 0,'nonmoral': 0,'nm': 0\n",
    "                                }})\n",
    "    return df\n",
    "\n",
    "def label_mp5(df):\n",
    "    df= df.replace({'label': {'care': 0, 'harm': 0,\n",
    "                                'fairness': 0,'cheating': 0,\n",
    "                                'loyalty': 0,'betrayal': 0,\n",
    "                                'authority': 0,'subversion': 0,\n",
    "                                 'purity': 1,'degradation': 2,'non-moral': 0,'nonmoral': 0,'nm': 0\n",
    "                                }})\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffab7bc-bf38-4cec-9ad7-cd2f9bf849d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp_label1():   \n",
    "    id2label = {0:\"NO-MORAL\", 1:\"CARE\" ,2:\"HARM\"}\n",
    "    label2id = {\"NO-MORAL\":0, \"CARE\":1 ,\"HARM\":2}\n",
    "    return id2label,label2id \n",
    "    \n",
    "def mp_label2():\n",
    "    id2label = {0:\"NO-MORAL\", 1:\"FAIRNESS\" ,2:\"CHEATING\"}\n",
    "    label2id = {\"NO-MORAL\":0, \"FAIRNESS\":1 ,\"CHEATING\":2}\n",
    "    return id2label,label2id \n",
    "    \n",
    "def mp_label3():\n",
    "    id2label = {0:\"NO-MORAL\", 1:\"LOYALTY\" ,2:\"BETRAYAL\"}\n",
    "    label2id = {\"NO-MORAL\":0, \"LOYALTY\":1 ,\"BETRAYAL\":2}\n",
    "    return id2label,label2id \n",
    "    \n",
    "def mp_label4():\n",
    "    id2label = {0:\"NO-MORAL\", 1:\"AUTHORITY\" ,2:\"SUBVERSION\"}\n",
    "    label2id = {\"NO-MORAL\":0, \"AUTHORITY\":1 ,\"SUBVERSION\":2}\n",
    "    return id2label,label2id \n",
    "    \n",
    "def mp_label5():\n",
    "    id2label = {0:\"NO-MORAL\", 1:\"PURITY\" ,2:\"DEGRADATION\"}\n",
    "    label2id = {\"NO-MORAL\":0, \"PURITY\":1 ,\"DEGRADATION\":2}\n",
    "    return id2label,label2id \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724aa14a-738c-4ea2-a100-71b457152274",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LABELS MULTICLASS 6 (MultiPres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f2a8075-1abb-46c7-819a-5f7f40d54bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the label from categorical to int using all moral traits at once. \n",
    "def label_multiclass6(df):\n",
    "    df= df.replace({'label': {'care': 1, 'harm': 1,\n",
    "                                'fairness': 2,'cheating': 2,\n",
    "                                'loyalty': 3,'betrayal': 3,\n",
    "                                'authority': 4,'subversion': 4,\n",
    "                                 'purity': 5,'degradation': 5,'non-moral': 0,'nonmoral': 0,'nm': 0\n",
    "                                }})\n",
    "    return df\n",
    "\n",
    "\n",
    "def multiclass_task_6():   \n",
    "    id2label = {0:\"NO-MORAL\", 1:\"CARE\" ,1:\"HARM\",2:\"FAIRNESS\",2:\"CHEATING\",3:\"LOYALTY\",3:\"BETRAYAL\",4:\"AUTHORITY\",4:\"SUBVERSION\",5:\"PURITY\",5:\"DEGRADATION\"}\n",
    "    label2id = {\"NO-MORAL\":0, \"CARE\": 1,\"HARM\":1,\"FAIRNESS\":2,\"CHEATING\":2,\"LOYALTY\":3,\"BETRAYAL\":3,\"AUTHORITY\":4,\"SUBVERSION\":4,\"PURITY\":5,\"DEGRADATION\":5}\n",
    "    return id2label,label2id \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2f8c37-946f-4c9c-a53f-06162f899bfc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LABELS MULTICLASS 11 (MultiPol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5ebb29-cc5b-401b-864f-ee8e15be5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the label from categorical to int using all moral traits at once, distinguishing the polarity (vice or virtue).\n",
    "def label_multiclass_11(df):\n",
    "    df= df.replace({'label': {'care': 1, 'harm': 2,\n",
    "                                'fairness': 3,'cheating': 4,\n",
    "                                'loyalty': 5,'betrayal': 6,\n",
    "                                'authority': 7,'subversion': 8,\n",
    "                                 'purity': 9,'degradation': 10,'non-moral': 0,'nonmoral': 0,'nm': 0\n",
    "                                }})\n",
    "    return df\n",
    "\n",
    "\n",
    "def multiclass_task_11():   \n",
    "    id2label = {0:\"NO-MORAL\", 1:\"CARE\" ,2:\"HARM\",3:\"FAIRNESS\",4:\"CHEATING\",5:\"LOYALTY\",6:\"BETRAYAL\",7:\"AUTHORITY\",8:\"SUBVERSION\",9:\"PURITY\",10:\"DEGRADATION\"}\n",
    "    label2id = {\"NO-MORAL\":0, \"CARE\":1 ,\"HARM\":2,\"FAIRNESS\":3,\"CHEATING\":4,\"LOYALTY\":5,\"BETRAYAL\":6,\"AUTHORITY\":7,\"SUBVERSION\":8,\"PURITY\":9,\"DEGRADATION\":10}\n",
    "    return id2label,label2id \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5649c7ad-b7ff-4641-9a12-a670722967a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# CLEAN DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb959439-1fb3-4b84-9c99-f4bc7a8a42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean and pre-process data\n",
    "'''Code from paper:\n",
    "Liscio, E., Dondera, A.E., Geadau, A., Jonker, C.M., Murukannaiah,\n",
    "P.K., 2022a. Cross-domain classification of moral values, in: 2022 Find-\n",
    "ings of the Association for Computational Linguistics: NAACL 2022,\n",
    "Association for Computational Linguistics (ACL). pp. 2727–2745\n",
    "\n",
    "[Source code] https://github.com/adondera/transferability-of-values/blob/master/nlp/data/cleaners.py\n",
    "'''\n",
    "\n",
    "\n",
    "text_processor = TextPreProcessor(\n",
    "    # terms that will be normalized\n",
    "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
    "               'time', 'url', 'date', 'number'],\n",
    "    # terms that will be annotated\n",
    "    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
    "              'emphasis', 'censored'},\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "\n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for word segmentation \n",
    "    segmenter=\"twitter\",\n",
    "\n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for spell correction\n",
    "    corrector=\"twitter\",\n",
    "\n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct_elong=True,  # spell correction for elongated words\n",
    "\n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "\n",
    "    # list of dictionaries, for replacing tokens extracted from the text,\n",
    "    # with other expressions. You can pass more than one dictionaries.\n",
    "    dicts=[emoticons]\n",
    ")\n",
    "\n",
    "tweet_processor = TextPreProcessor(\n",
    "    # terms that will be normalized\n",
    "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
    "               'time', 'url', 'date', 'number'],\n",
    "    # terms that will be annotated\n",
    "    annotate={},\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "\n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for word segmentation \n",
    "    segmenter=\"twitter\",\n",
    "\n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for spell correction\n",
    "    corrector=\"twitter\",\n",
    "\n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct_elong=True,  # spell correction for elongated words\n",
    "\n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "\n",
    "    # list of dictionaries, for replacing tokens extracted from the text,\n",
    "    # with other expressions. You can pass more than one dictionaries.\n",
    "    dicts=[emoticons]\n",
    ")\n",
    "\n",
    "# segmenter using the word statistics from Twitter\n",
    "seg_tw = Segmenter(corpus=\"twitter\")\n",
    "\n",
    "\n",
    "# This preprocessing method was used for our experiments.\n",
    "def cleaner5(tweet):\n",
    "    tweet = emoji.demojize(tweet)\n",
    "    tweet = \"\".join([char for char in tweet if char not in string.punctuation])\n",
    "    tweet = re.sub(r'amp', ' ', tweet)\n",
    "    return cleaner4(tweet)\n",
    "\n",
    "\n",
    "def cleaner4(tweet):\n",
    "    # remove pictures\n",
    "    tweet = re.sub(\"pic.twitter.com/[A-Za-z0-9]+\", \"\", tweet)\n",
    "\n",
    "    # rectification for Sandy\n",
    "    tweet = re.sub(\" url \", \"\", tweet)\n",
    "    tweet = re.sub(\" at_user \", \"\", tweet)\n",
    "\n",
    "    # remove numbers\n",
    "    tweet = re.sub(\"[0-9]+\", \"\", tweet)\n",
    "\n",
    "    # deabbreviate most used abbreviations\n",
    "    tweet = tweet.replace(\"#iuic\", \"#IsraelUnitedInChrist\")\n",
    "    tweet = tweet.replace(\"#tcot\", \"#TopConservativesOnTweeter\")\n",
    "\n",
    "    # custom preprocessor\n",
    "    tweet = \" \".join(tweet_processor.pre_process_doc(tweet))\n",
    "\n",
    "    # remove tags\n",
    "    tweet = re.sub(\"<[^\\s]+>\", \"\", tweet)\n",
    "    tweet = tweet.replace(\"_\", \" \")\n",
    "\n",
    "    # remove left usernames\n",
    "    tweet = re.sub(\"@[^\\s]+\", \"\", tweet)\n",
    "\n",
    "    # remove punctation\n",
    "\n",
    "    # remove reserved words\n",
    "    tweet = tweet.replace(\" rt \", \"\")\n",
    "    tweet = re.sub(\"^rt \", \"\", tweet)\n",
    "\n",
    "    # manual word corrections\n",
    "    tweet = tweet.replace(\" s \", \" is \").replace(\" al \", \" all \").replace(\" nt \", \" not \").replace(\" ppl \",\n",
    "                                                                                                   \" people \").replace(\n",
    "        \" m \", \" am \").replace(\" u \", \" you \").replace(\" r \", \" are \").replace(\" w \", \" with \")\n",
    "\n",
    "    # remove math signs\n",
    "    tweet = tweet.replace(\"+\", \"\").replace(\"=\", \"\").replace(\">\", \"\").replace(\"<\", \"\").replace(\"|\", \"\")\n",
    "    tweet = tweet.replace(\"https\", \"\").replace(\"http\", \"\")\n",
    "\n",
    "    # manual ALM and BLM word splitting\n",
    "    tweet = tweet.replace(\" alllivesmatter \", \" all lives matter \").replace(\" alm \", \" all lives matter \")\n",
    "    tweet = tweet.replace(\" blacklivesmatter \", \" black lives matter \").replace(\" blm \", \" black lives matter \")\n",
    "\n",
    "    # remove extra white spaces\n",
    "    tweet = \" \".join(tweet.split())\n",
    "    return tweet.lower()\n",
    "\n",
    "\n",
    "def cleaner3(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(\"^rt \", \"\", tweet)\n",
    "    tweet = re.sub(\"pic.twitter.com/[A-Za-z0-9]+\", \"\", tweet)\n",
    "    tweet = \" \".join(text_processor.pre_process_doc(tweet))\n",
    "    tweet = re.sub(\"<[^\\s]+>\", \"\", tweet)\n",
    "    tweet = tweet.strip()\n",
    "    tweet = \" \".join(tweet.split())\n",
    "    return tweet.lower()\n",
    "\n",
    "\n",
    "def cleaner2(tweet):\n",
    "    tweet = tweet.lstrip('\\\"')\n",
    "    tweet = tweet.rstrip('\\\"')\n",
    "    tweet = remove_emojis(tweet)\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(\"^rt\", \"\", tweet)\n",
    "    tweet = re.sub(\"\\s[0-9]+\\s\", \"\", tweet)\n",
    "\n",
    "    # remove usernames\n",
    "    tweet = re.sub(\"@[^\\s]+\", \"\", tweet)\n",
    "    tweet = re.sub(\"at_user\", \"\", tweet)\n",
    "\n",
    "    # remove # sign \n",
    "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \")\n",
    "\n",
    "    # remove urls\n",
    "    tweet = re.sub(\"pic.twitter.com/[A-Za-z0-9]+\", \"\", tweet)\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet)\n",
    "    tweet = tweet.replace(\"url\", \"\")\n",
    "\n",
    "    tweet = tweet.strip()\n",
    "    tweet = \" \".join(tweet.split())\n",
    "\n",
    "    return tweet\n",
    "\n",
    "\n",
    "def cleaner1(tweet):\n",
    "    # remove usernames\n",
    "    # tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet)\n",
    "    tweet = remove_emojis(tweet)\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(\"^rt\", \"\", tweet)\n",
    "    tweet = re.sub(\"\\s[0-9]+\\s\", \"\", tweet)\n",
    "\n",
    "    # remove usernames\n",
    "    tweet = re.sub(\"@[^\\s]+\", \"\", tweet)\n",
    "    tweet = re.sub(\"at_user\", \"\", tweet)\n",
    "\n",
    "    # remove # sign \n",
    "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \")\n",
    "\n",
    "    # remove urls\n",
    "    tweet = re.sub(\"pic.twitter.com/[A-Za-z0-9]+\", \"\", tweet)\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet)\n",
    "    tweet = tweet.replace(\"url\", \"\")\n",
    "\n",
    "    tweet = tweet.strip()\n",
    "    tweet = \" \".join(tweet.split())\n",
    "\n",
    "    return tweet\n",
    "\n",
    "\n",
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "                      u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                      u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                      u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                      u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                      u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                      u\"\\U00002702-\\U000027B0\"\n",
    "                      u\"\\U00002702-\\U000027B0\"\n",
    "                      u\"\\U000024C2-\\U0001F251\"\n",
    "                      u\"\\U0001f926-\\U0001f937\"\n",
    "                      u\"\\U00010000-\\U0010ffff\"\n",
    "                      u\"\\u2640-\\u2642\"\n",
    "                      u\"\\u2600-\\u2B55\"\n",
    "                      u\"\\u200d\"\n",
    "                      u\"\\u23cf\"\n",
    "                      u\"\\u23e9\"\n",
    "                      u\"\\u231a\"\n",
    "                      u\"\\ufe0f\"  # dingbats\n",
    "                      u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)\n",
    "\n",
    "def clean_data(df):\n",
    "    df['text']=df['text'].apply(lambda x: remove_emojis(x))\n",
    "    df['text']=df['text'].apply(lambda x: cleaner1(x))\n",
    "    df['text']=df['text'].apply(lambda x: cleaner2(x))\n",
    "    df['text']=df['text'].apply(lambda x: cleaner3(x))\n",
    "    df['text']=df['text'].apply(lambda x: cleaner4(x))\n",
    "    df['text']=df['text'].apply(lambda x: cleaner5(x))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc67dee-42bb-4d60-944a-58ab83994fb4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# New annotations MFTD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ece65e6-278e-4097-8f4c-912b921231b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create annotations with the distinction between vice and virtue MFTC\n",
    "Taking into account the annotations from the annotators and label the moral \n",
    "value that has the most agreement among the annotators.'''\n",
    "\n",
    "def label_column(row):\n",
    "    #select annotation values from dict\n",
    "    return list(x[\"annotation\"] for x in row)\n",
    "\n",
    "def annotation(row): \n",
    "    #list of anotations, count items type \n",
    "    annotation_list = list(x.split(',') for x in row)\n",
    "    final_list = [i for s in annotation_list for i in s]\n",
    "    annotation=max(Counter(final_list), key=(Counter(final_list)).get)\n",
    "    return annotation\n",
    "\n",
    "\n",
    "def new_labels_polarity(df):\n",
    "    df['annotations'] = df['annotations'].apply(lambda x: literal_eval(str(x)))\n",
    "    df['labels'] = df['annotations'].apply(label_column)\n",
    "    df['label_annotators'] = df.labels.apply(annotation)\n",
    "    df.label=df.label.replace({\"hate\": 'degradation','Care':'care','Harm':'harm','Fairness':'fairness','Cheating':'cheating','Loyalty':'loyalty','Betrayal':'betrayal','Authority':'authority','Subversion':'subversion','Purity':'purity','Degradation':'degradation','Non-moral':'non-moral','nm':'non-moral','Non-Moral':'non-moral'})\n",
    "    df.drop(['annotations', 'labels'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "#BLM dataset \n",
    "def process_labels(row):\n",
    "    try:\n",
    "        labels_list = row['labels']\n",
    "        if isinstance(labels_list, list) and len(labels_list) == 1:\n",
    "            label = ast.literal_eval(labels_list[0])\n",
    "            if isinstance(label, list):\n",
    "                return [x['annotation'] for x in label]\n",
    "    except (SyntaxError, ValueError, TypeError, KeyError):\n",
    "        pass  \n",
    "    return row['labels']\n",
    "\n",
    "\n",
    "def new_labels_blm_polarity(df):\n",
    "    '''add label'''\n",
    "    df['annotations'] = df['annotations'].apply(lambda x: literal_eval(str(x)))\n",
    "    df['labels'] = df['annotations'].apply(label_column)\n",
    "    df['labels'] = df.apply(process_labels, axis=1)\n",
    "    df['label_annotators'] = df.labels.apply(annotation)\n",
    "    df.label=df.label.replace({\"hate\": 'degradation','nm':'non-moral'})\n",
    "    df.drop(['annotations', 'labels'],axis=1,inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ebb135-86e9-4615-9ef5-97d8c623ab6a",
   "metadata": {},
   "source": [
    "# New annotations MFRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa4457-0af7-46f6-b3c2-b64e5503a772",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create annotations with the distinction between vice and virtue REDDIT\n",
    "Taking into account the annotations from the annotators and label the moral value \n",
    "that has the most agreement among the annotators.'''\n",
    "\n",
    "def annotation(row): \n",
    "    #list of anotations, count items type \n",
    "    annotation_list = list(x.split(',') for x in row)\n",
    "    final_list = [i for s in annotation_list for i in s]\n",
    "    annotation=max(Counter(final_list), key=(Counter(final_list)).get)\n",
    "    return annotation\n",
    "\n",
    "def clean_reddit_dataset(df):\n",
    "    df= df[df['annotation'] != 'Thin Morality']\n",
    "    df= df.groupby('text').agg(lambda x: list(x)).reset_index()\n",
    "    df['label']=df.annotation.apply(annotation)\n",
    "    df=df.drop(columns=['subreddit','bucket','annotator','confidence'])\n",
    "    df['label'] = df['label'].replace({'Proportionality': 'Fairness', 'Equality': 'Fairness'})\n",
    "    df.label=df.label.replace({'Care':'care','Harm':'harm','Fairness':'fairness','Cheating':'cheating','Loyalty':'loyalty','Betrayal':'betrayal','Authority':'authority','Subversion':'subversion','Purity':'purity','Degradation':'degradation','Non-moral':'non-moral','nm':'non-moral','Non-Moral':'non-moral'})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# REDDIT dataset pre-process\n",
    "anot=df.annotation.unique()\n",
    "annotation_list = list(x.split(',') for x in anot)\n",
    "new_list=list(itertools.chain(*annotation_list))\n",
    "c = collections.Counter(new_list)\n",
    "#filter, not to use thin morality\n",
    "df_reddit2 = reddit[reddit['annotation'] != 'Thin Morality']\n",
    "df_reddit3= clean_reddit_dataset(df_reddit2)\n",
    "df_reddit3['text'].astype(str)\n",
    "df_reddit = clean_data(df_reddit3)\n",
    "df_reddit\n",
    "#df_reddit.to_csv('DATASETS/REDDIT_clean.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
